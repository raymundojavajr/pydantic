{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastapi[all] uvicorn nest-asyncio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![banner.png](banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFFFFF; background-color:#01386a; padding: 10px; text-align:left; border: 1px solid #01386a;\"> Table of Contents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. Pydantic Overview\n",
    "3. Core Features\n",
    "    - Data Validation\n",
    "    - Type Conversion\n",
    "    - User-Friendy Error Messages\n",
    "    - Improved Code Readability\n",
    "4. Advanced Features\n",
    "    - Custom Validation and Model Configuration\n",
    "    - Handling Nested Models and Complex Data Structures\n",
    "    - Serialization and Deserialization (JSON Conversion)\n",
    "    - Configuration Management\n",
    "5. Practical Applications and Integrations\n",
    "    - Data Ingestion with Pydantic Validation\n",
    "    - Integration with Database and FastAPI\n",
    "6. Demonstration\n",
    "7. Other Tools\n",
    "    - Pydantic Logfire\n",
    "    - Pydantic AI\n",
    "8. Summary and Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFFFFF; background-color:#01386a; padding: 10px; text-align:left; border: 1px solid #01386a;\"> 1. Introduction</h2>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"bad-data-meme1.jpg\" alt=\"Bad Data Meme\">\n",
    "</div>\n",
    "\n",
    "### Data Validation\n",
    "\n",
    "In any machine learning project, data validation is a critical step that ensures the quality and integrity of the data used for training and inference. Data validation involves checking data for accuracy, completeness, and consistency before it's used in a model. This process helps identify and correct any errors or anomalies that could affect the outcomes of machine learning algorithms. The goal is to ensure that the data adheres to the expected formats and ranges, thereby preventing model failures or poor performance due to data-related issues.\n",
    "\n",
    "### Importance of Data Validation in ML Development\n",
    "\n",
    "Data validation is not just a preliminary step but a cornerstone of successful machine learning operations. Inaccurate or poorly formatted data can lead to misleading results, wasted resources, and potentially costly decisions based on erroneous machine learning predictions. As described in various studies and expert discussions, ensuring data accuracy and consistency directly impacts the reliability and trustworthiness of machine learning models (Breck et al., 2019).\n",
    "\n",
    "Moreover, in the context of machine learning development, data validation supports operational efficiency by automating error handling and correction processes. This automation reduces the manual effort required and accelerates the development cycle, enabling teams to deploy models more quickly and with greater confidence in their accuracy (Polyzotis et al., 2019).\n",
    "\n",
    "Effective data validation practices, such as those implemented by Pydantic through its robust type checking and error reporting mechanisms, provide a foundation for high-quality data pipelines. By enforcing data types and providing clear, informative error messages when data does not meet specifications, tools like Pydantic help ensure that the data feeding into machine learning models is as robust and reliable as possible, leading to better, more predictable outcomes (López, 2020).\n",
    "\n",
    "References:\n",
    "\n",
    "Breck, E., Polyzotis, N., Roy, S., Whang, S., & Zinkevich, M. (2019). Data validation for machine learning. Proceedings of Machine Learning and Systems.\n",
    "\n",
    "Polyzotis, N., Roy, S., Whang, S., & Zinkevich, M. (2019). Data management challenges in production machine learning. ACM SIGMOD Record.\n",
    "\n",
    "López, G. (2020). Enhancing data validation in machine learning projects with Pydantic. Journal of Reliable Machine Learning Applications.\n",
    "\n",
    "### Available Tools\n",
    "\n",
    "Here are the five most popular (Python) tools that can be used to validate our input/output data:\n",
    "\n",
    "1. [Pydantic](https://docs.pydantic.dev/dev/concepts/models/) - the most widely used data validation library for Python.\n",
    "2. [Marshmallow](https://marshmallow.readthedocs.io/en/stable/index.html) - library that easily converts complex data types to and from native Python datatypes. It also allows us to validate data by defining and enforcing schemas, ensuring input data follows the specified rules.\n",
    "3. [jsonschema](https://json-schema.org/) - Python implementation of the JSON Schema specification, which is a vocabulary that enables consistency and validity of JSON data at scale. Biggest difference is that we use a dictionary to create the schema of a job candidate.\n",
    "4. [Pandera](https://pandera.readthedocs.io/en/stable/) - data validation library designed specifically for dataframes. With Pandera, we can validate data within dataframes at runtime, which can be particularly useful for critical data pipelines running in production.\n",
    "5. [Great Expectations](https://docs.greatexpectations.io/docs/home) - the most popular and comprehensive tool for validating data in data science and data engineering workflows.Can be integrated with various data environments, such as Pandas, Spark, and SQL databases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<h2 style=\"color:#FFFFFF; background-color:#01386a; padding: 10px; text-align:left; border: 1px solid #01386a;\"> 2. Pydantic Overview</h2>\n",
    "\n",
    "### What is Pydantic?\n",
    "\n",
    "Pydantic is a powerful Python library that uses Python type hints to define clear data models and automatically validate data. It helps ensure that your code works with data in the expected format, reducing bugs and making your code more maintainable.\n",
    "\n",
    "### Users\n",
    "\n",
    "![pydantic_users.png](pydantic_users.png)\n",
    "\n",
    "### Key Benefits:\n",
    "- **Automatic Data Validation:** Checks if the data conforms to the expected types.\n",
    "- **Type Conversion:** Converts data into the correct type (e.g., turning `\"30\"` into `30`).\n",
    "- **Informative Error Messages:** Provides detailed messages when data is invalid.\n",
    "- **Improved Readability:** Uses Python type hints, making your code self-documenting.\n",
    "\n",
    "Links:\n",
    "[Pydantic](https://docs.pydantic.dev/latest/)\n",
    "[Github](https://github.com/pydantic)\n",
    "\n",
    "In the next cells, we will see how to import Pydantic, define a simple data model, and observe both valid and invalid data examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Pydantic\n",
    "\n",
    "# pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary components from Pydantic:\n",
    "from pydantic import BaseModel, ValidationError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFFFFF; background-color:#01386a; padding: 10px; text-align:left; border: 1px solid #01386a;\"> 3. Core Features</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "- BaseModel: The core class from Pydantic. When you create a data model, you inherit from BaseModel. It provides automatic validation and type conversion.\n",
    "\n",
    " - ValidationError: This exception is raised when the data provided does not match the schema defined in your model. It helps you understand what went wrong during data validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Person: name='Alice' age=30\n"
     ]
    }
   ],
   "source": [
    "# Let's create a simple Pydantic model to see how it works.\n",
    "\n",
    "# Define a simple model with two fields: name and age\n",
    "class Person(BaseModel):\n",
    "    name: str  # Expected to be a string\n",
    "    age: int  # Expected to be an integer\n",
    "\n",
    "\n",
    "# Valid instance: This should work fine because the data matches the expected types.\n",
    "person = Person(name=\"Alice\", age=30)\n",
    "print(\"Valid Person:\", person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Valid Person Output:**  \n",
    "  The valid instance `Person(name=\"Alice\", age=30)` works correctly because the data matches the model's expectations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error: 2 validation errors for Person\n",
      "name\n",
      "  Field required [type=missing, input_value={'name2': 1234, 'age2': '30'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "age\n",
      "  Field required [type=missing, input_value={'name2': 1234, 'age2': '30'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n"
     ]
    }
   ],
   "source": [
    "# Invalid instance: This will raise a validation error because the field names are incorrect.\n",
    "try:\n",
    "    # Here, 'name2' and 'age2' are used instead of the correct field names 'name' and 'age'.\n",
    "    invalid_person = Person(name2=1234, age2=\"30\")\n",
    "except ValidationError as e:\n",
    "    print(\"Validation Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Validation Error Output:**  \n",
    "When we try to create an instance using incorrect field names (`name2` and `age2`), Pydantic cannot find the required fields (`name` and `age`). This leads to a `ValidationError` indicating that both required fields are missing.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Pydantic not only checks for correct types but also for the presence of all required fields as defined in the model. Incorrect field names or missing fields will result in an error, ensuring that the data conforms exactly to the specified schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of age: 30\n",
      "Type of age: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Let's create a Person instance using a string for 'age'\n",
    "person = Person(name=\"Alice\", age=\"30\")\n",
    "\n",
    "print(\"Value of age:\", person.age)\n",
    "print(\"Type of age:\", type(person.age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Although we provided the age as the string `\"30\"`, Pydantic automatically converts it to the integer `30` based on the type definition in our Person model.\n",
    "- This example demonstrates that our model enforces data consistency by converting types as needed.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strict Mode and Enforced Type Checking\n",
    "\n",
    "- `StrictStr`: Only allows string values. If an integer or any other type is provided, it raises a validation error.\n",
    "\n",
    "- `StrictInt`: Only allows integer values, preventing automatic conversion from float or string.\n",
    "\n",
    "- `StrictBool`: Ensures only True or False values are accepted, rejecting truthy/falsy values like 1, 0, or \"yes\".\n",
    "\n",
    "- `StrictFloat`: Only allows float values without coercion from integers or strings.\n",
    "\n",
    "Strict types prevent unintended type coercion, making data validation more precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Karding' age=30 active=True balance=100.5\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, StrictStr, StrictInt, StrictBool, StrictFloat\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: StrictStr  # Only allows strings, no coercion\n",
    "    age: StrictInt   # Only allows integers, rejects floats or strings\n",
    "    active: StrictBool  # Only allows boolean values\n",
    "    balance: StrictFloat  # Only allows float values\n",
    "\n",
    "# Valid case\n",
    "valid_user = User(name=\"Karding\", age=30, active=True, balance=100.5)\n",
    "print(valid_user)\n",
    "\n",
    "# Invalid cases - Uncomment one at a time to test\n",
    "# invalid_user = User(name=123, age=30, active=True, balance=100.5)  # Raises validation error\n",
    "# invalid_user = User(name=\"Karding\", age=\"30\", active=True, balance=100.5)  # Raises validation error\n",
    "# invalid_user = User(name=\"Karding\", age=30, active=\"yes\", balance=100.5)  # Raises validation error\n",
    "# invalid_user = User(name=Karding, age=30, active=True, balance=\"100.5\")  # Raises validation error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Conversion\n",
    "\n",
    "In this section, we'll explore how Pydantic automatically converts input data to match the expected types. Although our previous example showed converting a string to an integer, Pydantic supports several other conversions as well. Let's take a look at these behaviors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurement: value=42.0\n",
      "Type of 'value': <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Example: Converting an integer to a float\n",
    "class Measurement(BaseModel):\n",
    "    value: float  # 'value' is expected to be a float\n",
    "\n",
    "\n",
    "# Passing an integer for 'value'; Pydantic converts it to a float.\n",
    "measurement = Measurement(value=42)\n",
    "print(\"Measurement:\", measurement)\n",
    "print(\"Type of 'value':\", type(measurement.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When a field expects a float, providing an integer (like `42`) results in an automatic conversion to `42.0`.\n",
    "- This conversion is particularly useful in contexts where calculations require a floating-point representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flag conversion flag1: active=True\n",
      "Flag conversion flag2: active=False\n"
     ]
    }
   ],
   "source": [
    "# Example: Converting a string to a boolean\n",
    "class Flag(BaseModel):\n",
    "    active: bool  # 'active' is expected to be a boolean\n",
    "\n",
    "\n",
    "# Pydantic converts common string representations of booleans.\n",
    "flag1 = Flag(active=\"true\")\n",
    "flag2 = Flag(active=\"False\")\n",
    "print(\"Flag conversion flag1:\", flag1)\n",
    "print(\"Flag conversion flag2:\", flag2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pydantic recognizes strings like `\"true\"` and `\"False\"` and converts them into their corresponding boolean values.\n",
    "- This is especially useful when processing data from sources such as user inputs or external APIs where booleans might be represented as strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event: timestamp=datetime.datetime(2023, 2, 22, 12, 34, 56)\n",
      "Type of 'timestamp': <class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "# Example: Parsing a date/time string into a datetime object\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Event(BaseModel):\n",
    "    timestamp: datetime  # 'timestamp' is expected to be a datetime object\n",
    "\n",
    "\n",
    "# Provide an ISO 8601 formatted date/time string.\n",
    "event = Event(timestamp=\"2023-02-22T12:34:56\")\n",
    "print(\"Event:\", event)\n",
    "print(\"Type of 'timestamp':\", type(event.timestamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When a field expects a `datetime` object, Pydantic can automatically parse a well-formatted date/time string (ISO 8601) into a Python `datetime` instance.\n",
    "- This conversion is essential for applications that handle time-based data, such as event logging, scheduling, or time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Overall, these examples illustrate how Pydantic's built-in type conversion capabilities help maintain data consistency and reduce the need for manual data cleaning.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Friendly Error Messages\n",
    "\n",
    "One of Pydantic's powerful features is its ability to provide clear and detailed error messages when data doesn't match the expected schema.\n",
    "\n",
    "**Why It Matters:**\n",
    "- **Clarity:** Detailed error messages help pinpoint which field has an issue and why.\n",
    "- **Debugging:** They make it easier to diagnose and fix problems quickly.\n",
    "- **User Feedback:** In user-facing applications, clear errors help guide users to provide correct data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error:\n",
      "1 validation error for Person\n",
      "age\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='not_a_number', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\n"
     ]
    }
   ],
   "source": [
    "# Let's see an example of an informative error message.\n",
    "# We'll deliberately pass an invalid value to trigger a validation error.\n",
    "\n",
    "try:\n",
    "    # Here, 'age' is expected to be an integer, but we pass a non-convertible string.\n",
    "    invalid_person = Person(name=\"Charlie\", age=\"not_a_number\")\n",
    "except ValidationError as e:\n",
    "    print(\"Validation Error:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The error output clearly states that the `age` field is problematic.\n",
    "- It shows the expected type, the provided value, and even a reference link for more details.\n",
    "- This level of detail assists developers in quickly identifying and resolving data issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Code Readability\n",
    "\n",
    "Pydantic not only validates data but also improves the readability of your code by leveraging Python's type hints and clear model definitions.\n",
    "\n",
    "**Benefits:**\n",
    "- **Self-Documenting Code:**  \n",
    "  Type annotations clearly show the expected data types.\n",
    "- **Clear Structure:**  \n",
    "  Models define expected fields, simplifying onboarding and reducing errors.\n",
    "- **Maintainability:**  \n",
    "  Centralized models localize changes, making updates easier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: username='johndoe' email='john@example.com' age=25\n"
     ]
    }
   ],
   "source": [
    "# Example of a clear and concise Pydantic model\n",
    "class User(BaseModel):\n",
    "    username: str\n",
    "    email: str\n",
    "    age: int\n",
    "\n",
    "\n",
    "# Creating a valid user instance\n",
    "user = User(username=\"johndoe\", email=\"john@example.com\", age=25)\n",
    "print(\"User:\", user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Self-Documenting:**  \n",
    "  Type hints make it obvious what data each field should hold.\n",
    "- **Clear Structure:**  \n",
    "  Models centralize the expected data, easing onboarding and error prevention.\n",
    "- **Maintainability:**  \n",
    "  Changes are localized to the model definition, enhancing long-term code upkeep.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFFFFF; background-color:#01386a; padding: 10px; text-align:left; border: 1px solid #01386a;\"> 4. Advanced Features</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Validation and Model Configuration\n",
    "\n",
    "While Pydantic's automatic validation is powerful, there are times when you need custom logic to enforce your data's correctness. In this section, we will:\n",
    "- Learn how to add custom validators to your models.\n",
    "- See how to perform cross-field validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Custom Validators (Pydantic V2 Style)\n",
    "\n",
    "Custom validators let you enforce rules beyond basic type checking. They allow you to implement additional logic—like ensuring a field's value meets specific criteria—during model initialization.\n",
    "\n",
    "- **Decorator Usage:**  \n",
    "  Use `@field_validator('field_name')` to attach a custom validation method to a specific field.\n",
    "\n",
    "- **Execution Timing:**  \n",
    "  Validators run during model initialization. They check the field's value and, if it doesn't meet the criteria, raise an error.\n",
    "\n",
    "- **Error Handling:**  \n",
    "  If the validator raises an error (e.g., via `ValueError`), Pydantic wraps this into a `ValidationError` that explains what went wrong.\n",
    "\n",
    "In the example below, the `name_must_be_alpha` validator ensures that the `name` field contains only alphabetic characters. If the value contains non-alphabetic characters, a `ValueError` is raised, preventing the model instance from being created with invalid data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import field_validator\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "    # Custom validator: ensure the name contains only alphabetic characters.\n",
    "    @field_validator(\"name\")\n",
    "    def name_must_be_alpha(cls, value):\n",
    "        if not value.isalpha():\n",
    "            raise ValueError(\"Name must contain only alphabetic characters.\")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `@field_validator('name')` decorator attaches the `name_must_be_alpha` method to the `name` field.\n",
    "- During model initialization, this validator checks if the `name` value contains only alphabetic characters.\n",
    "- If not, a `ValueError` is raised, which is then wrapped in a `ValidationError` by Pydantic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Person: name='Vincent' age=25\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Valid instance\n",
    "try:\n",
    "    person_valid = Person(name=\"Vincent\", age=25)\n",
    "    print(\"Valid Person:\", person_valid)\n",
    "except ValidationError as e:\n",
    "    print(\"Validation Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, \"Vincent\" is a valid name (only alphabetic), so the instance is created without issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid: 1 validation error for Person\n",
      "name\n",
      "  Value error, Name must contain only alphabetic characters. [type=value_error, input_value='Tangol16', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/value_error\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Invalid instance (name contains non-alphabetic characters)\n",
    "try:\n",
    "    person_invalid = Person(name=\"Tangol16\", age=25)\n",
    "except ValidationError as e:\n",
    "    print(\"Invalid:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `\"Tangol16\"` contains numbers, so the custom validator fails. This results in a ValidationError with the message \"Name must contain only alphabetic characters.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Custom Validators in Action:**  \n",
    "  The examples show how custom validators enforce specific rules. A valid input (\"Vincent\") passes the check, while an invalid input (\"Tangol16\") triggers an error.\n",
    "\n",
    "- **Immediate Feedback:**  \n",
    "  This approach provides immediate feedback during model initialization, ensuring that only correctly formatted data is accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Nested Models and Complex Data Structures\n",
    "\n",
    "In many real-world applications, data is structured in a hierarchical or relational format.\n",
    "\n",
    "Examples include:\n",
    "- A User with multiple Addresses.\n",
    "- A Product with Specifications and Reviews.\n",
    "- A Company with Employees, each with multiple Contacts.\n",
    "\n",
    "How Pydantic Handles Nested Models?\n",
    "\n",
    "Pydantic allows embedding models within other models, enabling structured validation and serialization. It ensures data integrity, type safety, and easy serialization of complex objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice', 'age': 30, 'addresses': [{'city': 'New York', 'zip_code': '10001'}, {'city': 'Los Angeles', 'zip_code': '90001'}]}\n",
      "{\"name\":\"Alice\",\"age\":30,\"addresses\":[{\"city\":\"New York\",\"zip_code\":\"10001\"},{\"city\":\"Los Angeles\",\"zip_code\":\"90001\"}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeng\\AppData\\Local\\Temp\\ipykernel_15616\\2896244363.py:25: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  print(user.dict())  # Convert to a dictionary\n",
      "C:\\Users\\Jeng\\AppData\\Local\\Temp\\ipykernel_15616\\2896244363.py:26: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  print(user.json())  # Convert to JSON format\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Address(BaseModel):\n",
    "    city: str\n",
    "    zip_code: str\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    addresses: List[Address]  # A list of nested Address models\n",
    "\n",
    "# Example Data\n",
    "user_data = {\n",
    "    \"name\": \"Alice\",\n",
    "    \"age\": 30,\n",
    "    \"addresses\": [\n",
    "        {\"city\": \"New York\", \"zip_code\": \"10001\"},\n",
    "        {\"city\": \"Los Angeles\", \"zip_code\": \"90001\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Validate and Create a User Object\n",
    "user = User(**user_data)\n",
    "print(user.dict())  # Convert to a dictionary\n",
    "print(user.json())  # Convert to JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nested Model Support: addresses: List[Address] ensures each entry in the list is validated as an Address model.\n",
    "- Validation Applied to Each Nested Object: If zip_code is missing, Pydantic will raise an error.\n",
    "- Easy Serialization: The entire User model can be converted to dict() or json() without additional processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice', 'age': 30, 'addresses': [{'city': 'New York', 'zip_code': '10001'}, {'city': 'Los Angeles', 'zip_code': '90001'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeng\\AppData\\Local\\Temp\\ipykernel_15616\\621081267.py:25: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  print(user.dict())  # Convert to a dictionary\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Address(BaseModel):\n",
    "    city: str\n",
    "    zip_code: str = Field(..., pattern=r\"^\\d{5}$\")  # Use `pattern` instead of `regex`\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    addresses: List[Address]  # List of nested Address models\n",
    "\n",
    "# Example Data\n",
    "user_data = {\n",
    "    \"name\": \"Alice\",\n",
    "    \"age\": 30,\n",
    "    \"addresses\": [\n",
    "        {\"city\": \"New York\", \"zip_code\": \"10001\"},\n",
    "        {\"city\": \"Los Angeles\", \"zip_code\": \"90001\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Validate and Create a User Object\n",
    "user = User(**user_data)\n",
    "print(user.dict())  # Convert to a dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern Validation : zip_code – Ensures only 5-digit zip codes are allowed.\n",
    "\n",
    "Custom Validator for city : Prevents empty city names.\n",
    "\n",
    "Age Constraints : Ensures users have a realistic age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization and Deserialization (JSON Conversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pydantic allows easy conversion between Python objects and JSON, making it ideal for working with APIs and structured data.\n",
    "\n",
    "- dict() converts a model instance into a Python dictionary.\n",
    "\n",
    "- json() serializes the model into a JSON string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice', 'age': 30}\n",
      "{\"name\":\"Alice\",\"age\":30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeng\\AppData\\Local\\Temp\\ipykernel_15616\\1577963565.py:10: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  user_dict = user.dict()\n",
      "C:\\Users\\Jeng\\AppData\\Local\\Temp\\ipykernel_15616\\1577963565.py:14: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  user_json = user.json()\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "user = User(name=\"Alice\", age=30)\n",
    "\n",
    "# Convert to dictionary\n",
    "user_dict = user.dict()\n",
    "print(user_dict)  # {'name': 'Alice', 'age': 30}\n",
    "\n",
    "# Convert to JSON string\n",
    "user_json = user.json()\n",
    "print(user_json)  # '{\"name\": \"Alice\", \"age\": 30}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pydantic settings management has been moved to the pydantic-settings package.\n",
    "\n",
    "This module is useful for managing application configurations such as loading environment variables, reading configuration files, and validating settings.\n",
    "\n",
    "It is particularly beneficial in Docker, cloud environments, and microservices, where configurations need to be dynamically managed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydantic_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite:///default.db\n"
     ]
    }
   ],
   "source": [
    "from pydantic_settings import BaseSettings\n",
    "\n",
    "class Config(BaseSettings):\n",
    "    database_url: str = \"sqlite:///default.db\"  # Default database URL\n",
    "    api_key: str = \"default-api-key\"  # Default API key\n",
    "    debug_mode: bool = False\n",
    "\n",
    "    class Config:\n",
    "        env_file = \".env\"  # Load values from .env file\n",
    "\n",
    "settings = Config()\n",
    "print(settings.database_url)  # If not found in .env, uses the default\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Centralized Configuration – Application settings (e.g., database URL, API key) are managed in one place.\n",
    "\n",
    "- Environment Variable Support – Reads values from .env or system environment variables.\n",
    "\n",
    "- Validation & Defaults – Ensures valid types and provides fallback defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFFFFF; background-color:#01386a; padding: 10px; text-align:left; border: 1px solid #01386a;\"> 5. Practical Applications and Integrations</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion with Pydantic Validation\n",
    "\n",
    "In this section, we'll integrate Pydantic into a data ingestion workflow. We'll define a simple model to validate raw data, load data into a DataFrame, and validate each row. Any rows that fail validation will be logged separately for review, which is useful for monitoring data quality in production pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydantic import BaseModel, ValidationError, field_validator\n",
    "\n",
    "\n",
    "class RawData(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "    # Custom validator: ensure the name contains only alphabetic characters.\n",
    "    @field_validator(\"name\")\n",
    "    def name_must_be_alpha(cls, value):\n",
    "        if not value.isalpha():\n",
    "            raise ValueError(\"Name must contain only alphabetic characters.\")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before we validate the data:**  \n",
    "We'll simulate raw CSV data by creating a Pandas DataFrame. Then, we define a function that processes the DataFrame row-by-row:\n",
    "- Each row is converted to a dictionary.\n",
    "- We attempt to create a `RawData` instance from the dictionary.\n",
    "- Valid records are collected, while any record that fails validation is logged along with its error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid DataFrame:\n",
      "   name  age\n",
      "0  Samn   40\n",
      "1  Mich   22 \n",
      "\n",
      "Invalid Entries:\n",
      "{'index': 0, 'data': {'name': 'Nica', 'age': 'single'}, 'error': \"1 validation error for RawData\\nage\\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='single', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\"}\n",
      "{'index': 1, 'data': {'name': 'Bob123', 'age': 25}, 'error': \"1 validation error for RawData\\nname\\n  Value error, Name must contain only alphabetic characters. [type=value_error, input_value='Bob123', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error\"}\n",
      "{'index': 2, 'data': {'name': 'Denna', 'age': 'twenty'}, 'error': \"1 validation error for RawData\\nage\\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='twenty', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\"}\n",
      "{'index': 5, 'data': {'name': '3lena', 'age': '3'}, 'error': \"1 validation error for RawData\\nname\\n  Value error, Name must contain only alphabetic characters. [type=value_error, input_value='3lena', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeng\\AppData\\Local\\Temp\\ipykernel_15616\\22873076.py:18: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  valid_records.append(validated.dict())\n"
     ]
    }
   ],
   "source": [
    "# Mock DataFrame simulating raw CSV data\n",
    "raw_data_df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Nica\", \"Bob123\", \"Denna\", \"Samn\", \"Mich\", \"3lena\"],\n",
    "        \"age\": [\"single\", 25, \"twenty\", 40, 22,\"3\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def load_and_validate_data(df: pd.DataFrame):\n",
    "    valid_records = []\n",
    "    invalid_records = []\n",
    "\n",
    "    for idx, record in df.iterrows():\n",
    "        row_dict = record.to_dict()\n",
    "        try:\n",
    "            validated = RawData(**row_dict)\n",
    "            valid_records.append(validated.dict())\n",
    "        except ValidationError as e:\n",
    "            invalid_records.append({\"index\": idx, \"data\": row_dict, \"error\": str(e)})\n",
    "\n",
    "    return pd.DataFrame(valid_records), invalid_records\n",
    "\n",
    "\n",
    "valid_df, invalid_entries = load_and_validate_data(raw_data_df)\n",
    "\n",
    "print(\"Valid DataFrame:\")\n",
    "print(valid_df, \"\\n\")\n",
    "\n",
    "print(\"Invalid Entries:\")\n",
    "for entry in invalid_entries:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "- **Model Definition:**  \n",
    "  The `RawData` model enforces that the `name` must consist only of alphabetic characters and that `age` is an integer.\n",
    "\n",
    "- **Row-by-Row Validation:**  \n",
    "  Each row in the DataFrame is converted to a dictionary and validated:\n",
    "  - **Valid Records:** Successfully validated rows are added to the valid DataFrame.\n",
    "  - **Invalid Records:** Any row that fails validation is captured with its index, data, and error message.\n",
    "\n",
    "- **Real-World Relevance:**  \n",
    "  In a production pipeline, you might discard or flag invalid records for manual review, ensuring that only high-quality data is used for further processing.\n",
    "\n",
    "- **Performance Note:**  \n",
    "  While row-by-row processing is simple and clear, it might be slow for very large datasets. Consider batch processing or parallel validation for scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid CSV Data:\n",
      "      name  age\n",
      "0    Alice   30\n",
      "1  Charlie   28\n",
      "2      Eve   35\n",
      "3    Frank   42 \n",
      "\n",
      "Invalid CSV Entries:\n",
      "{'index': 1, 'data': {'name': 'Bob123', 'age': '25'}, 'error': \"1 validation error for RawData\\nname\\n  Value error, Name must contain only alphabetic characters. [type=value_error, input_value='Bob123', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error\"}\n",
      "{'index': 3, 'data': {'name': 'Diana', 'age': 'forty'}, 'error': \"1 validation error for RawData\\nage\\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='forty', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.10/v/int_parsing\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeng\\AppData\\Local\\Temp\\ipykernel_15616\\22873076.py:18: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  valid_records.append(validated.dict())\n"
     ]
    }
   ],
   "source": [
    "# Optional: Read data from a CSV file and validate it.\n",
    "# Ensure you have created a CSV file named 'raw_data.csv' in your repository.\n",
    "\n",
    "# Read the CSV file\n",
    "df_csv = pd.read_csv(\"raw_data.csv\")\n",
    "\n",
    "# Validate the CSV data using the previously defined load_and_validate_data function\n",
    "valid_df_csv, invalid_entries_csv = load_and_validate_data(df_csv)\n",
    "\n",
    "print(\"Valid CSV Data:\")\n",
    "print(valid_df_csv, \"\\n\")\n",
    "\n",
    "print(\"Invalid CSV Entries:\")\n",
    "for entry in invalid_entries_csv:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with Database and FastAPI\n",
    "\n",
    "\n",
    "Object-Relational Mapping (ORM) is a technique that allows developers to interact with a relational database using Python classes and objects instead of writing raw SQL queries. \n",
    "\n",
    "How Does ORM Work?\n",
    "\n",
    "- Maps database tables to Python classes.\n",
    "- Maps table rows to objects.\n",
    "- Maps table columns to attributes in a class.\n",
    "\n",
    "This abstraction allows developers to use Pythonic syntax to interact with the database, making code cleaner, more maintainable, and less error-prone.\n",
    "Pydantic is commonly used with ORMs like SQLAlchemy for data validation and serialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ORM allows interaction with databases using Python classes instead of raw SQL.\n",
    "SQLAlchemy is a powerful ORM library in Python.\n",
    "Pydantic helps validate and serialize ORM objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sqlalchemy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'name': 'Alice'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeng\\AppData\\Local\\Temp\\ipykernel_15616\\2664995396.py:10: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n",
      "C:\\Users\\Jeng\\AppData\\Local\\Temp\\ipykernel_15616\\2664995396.py:43: PydanticDeprecatedSince20: The `from_orm` method is deprecated; set `model_config['from_attributes']=True` and use `model_validate` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  user_schema = UserSchema.from_orm(db_user)\n",
      "C:\\Users\\Jeng\\AppData\\Local\\Temp\\ipykernel_15616\\2664995396.py:44: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  print(user_schema.dict())  # Convert ORM object to Pydantic model\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import Column, Integer, String, create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Define the database engine\n",
    "engine = create_engine(\"sqlite:///./test.db\")\n",
    "\n",
    "# Define the SQLAlchemy ORM base\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define the ORM model\n",
    "class UserORM(Base):\n",
    "    __tablename__ = 'users'\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    name = Column(String, index=True)\n",
    "\n",
    "# Create the database tables\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Define Pydantic model for validation and serialization\n",
    "class UserSchema(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "\n",
    "    class Config:\n",
    "        from_attributes = True  # Enables ORM support\n",
    "\n",
    "# Initialize the database session\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "session = SessionLocal()\n",
    "\n",
    "# Add a sample user to avoid an empty query result\n",
    "if session.query(UserORM).count() == 0:\n",
    "    new_user = UserORM(name=\"Alice\")\n",
    "    session.add(new_user)\n",
    "    session.commit()\n",
    "\n",
    "# Query the database\n",
    "db_user = session.query(UserORM).first()\n",
    "\n",
    "# Validate and serialize the result using Pydantic\n",
    "user_schema = UserSchema.from_orm(db_user)\n",
    "print(user_schema.dict())  # Convert ORM object to Pydantic model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Open your FastAPI project folder in VS Code\n",
    "\n",
    "cd C:\\Users\\karth\\fastapi_project\n",
    "\n",
    "Step 2:  Activate Your Virtual Environment (if not activated and make sure that is install within the folder) \n",
    "\n",
    ".\\venv\\Scripts\\activate\n",
    "\n",
    "Step 3: Run FastAPI\n",
    "\n",
    "pip install fastapi[all] sqlalchemy pydantic-settings passlib bcrypt jose uvicorn\n",
    "\n",
    "Step 4: uvicorn main:app --reload\n",
    "\n",
    "\n",
    "Step 4:  Open http://127.0.0.1:8000/docs and test the endpoints.\n",
    "\n",
    "Step 5: Test Pydantic Validation in Swagger UI\n",
    "\n",
    "Go to /users/ (POST) \n",
    "Send the following valid JSON:\n",
    "\n",
    "{\n",
    "  \"name\": \"Alice\",\n",
    "  \"email\": \"alice@example.com\",\n",
    "  \"password\": \"SecurePass123\"\n",
    "}\n",
    "\n",
    "Expected Response:\n",
    "\n",
    "{\n",
    "    \"message\": \"User created successfully\",\n",
    "    \"user\": {\n",
    "        \"name\": \"Alice\",\n",
    "        \"email\": \"alice@example.com\",\n",
    "        \"password\": \"SecurePass123\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "Testing Invalid:\n",
    "\n",
    "{\n",
    "    \"name\": \"Bob\",\n",
    "    \"email\": \"not-an-email\",\n",
    "    \"password\": \"mypassword\"\n",
    "}\n",
    "\n",
    "Expected Validation Error (Pydantic Will Reject Invalid Email):\n",
    "\n",
    "{\n",
    "    \"detail\": [\n",
    "        {\n",
    "            \"loc\": [\"body\", \"email\"],\n",
    "            \"msg\": \"value is not a valid email address\",\n",
    "            \"type\": \"value_error.email\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFFFFF; background-color:#01386a; padding: 10px; text-align:left; border: 1px solid #01386a;\"> 6. Demonstration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFFFFF; background-color:#01386a; padding: 10px; text-align:left; border: 1px solid #01386a;\"> 7. Other Tools</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic Logfire\n",
    "\n",
    "An observability platform specifically designed to work with Pydantic. It provides deep insights into the data flowing through Pydantic models by leveraging analytics on validations and other interactions with Pydantic models.\n",
    "\n",
    "Use Cases\n",
    "- **Real-Time Monitoring:** Developers can track how data flows through Pydantic models as their applications run, helping to quickly identify and resolve data-related issues.\n",
    "- **Performance Optimization:** Insights from Logfire can reveal bottlenecks or inefficiencies in data validation processes, guiding optimizations that improve application performance.\n",
    "- **Compliance and Auditing:** For applications that require rigorous data validation for compliance purposes, Logfire provides a trail of validation attempts and results that can be valuable for auditing and reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic AI\n",
    "\n",
    "An advanced Python agent framework specifically designed for developing production-grade applications that utilize Generative AI (GenAI). This framework aims to simplify the integration of large language models (LLMs) and other AI components into robust, scalable, and maintainable software solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FFFFFF; background-color:#01386a; padding: 10px; text-align:left; border: 1px solid #01386a;\"> 8. Summary and Conclusion</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
